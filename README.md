# Procesamiento Distribuido con Apache Spark

## Descripción

Este repositorio introduce el entorno de **Apache Spark** como una herramienta fundamental para el **procesamiento distribuido de datos** en el contexto de la ciencia de datos. A lo largo del contenido se estudia la arquitectura de Spark y su modelo de ejecución, con el objetivo de comprender el funcionamiento interno del sistema y cómo gestiona grandes volúmenes de datos de manera eficiente.

Además, se analizan las distintas **API que ofrece Apache Spark**, sus diferencias clave y los escenarios en los que resulta más adecuado utilizar cada una. Finalmente, se incluye la **implementación práctica de soluciones de procesamiento distribuido**, aplicando los conceptos teóricos abordados.

## Objetivos de Aprendizaje

Al finalizar el estudio y uso de este repositorio, se espera que el lector sea capaz de:

- Identificar la **arquitectura de Apache Spark** y su **modelo de ejecución**.
- Comprender las **API de Spark**, sus diferencias fundamentales y los **casos de uso** de cada interfaz.
- Implementar **procesamiento distribuido de datos** utilizando Apache Spark.

## Tecnologías Utilizadas

- Apache Spark  
- Procesamiento Distribuido de Datos  
- Ciencia de Datos  

## Alcance

Este repositorio está orientado a estudiantes y profesionales que deseen adquirir una base sólida en procesamiento distribuido utilizando Apache Spark, combinando fundamentos teóricos con ejercicios prácticos.
